{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataScienceWorkshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raquelaoki/DataScienceForFun/blob/master/TryCatch2019/DataScienceWorkshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP4lrmX5mHfi",
        "colab_type": "text"
      },
      "source": [
        "Presentation Link: https://docs.google.com/presentation/d/1stycVGd0RHCH9p0wX_cP_OkKFzy8PaU0SKCQWNVRYtc/edit?usp=sharing \n",
        "_________\n",
        "# Try/CATCH 2019\n",
        "\n",
        "### Raquel Aoki and Sashini Herath\n",
        "\n",
        "This Exercises is based on Professor Greg Baker class notes. \n",
        "\n",
        "## Pup Inflation: Analysing Tweets\n",
        "\n",
        "This question is heavily inspired by David H. Montgomery's Pup Inflation post. His analysis is an excellent data science task, and we will ask the same question here: has there been grade inflation on the @dog_rates Twitter, which rates the cuteness of users' dog pictures?\n",
        "\n",
        "We have the file dog_rates_tweets.csv with some of the twittes from this profile. To look for score inflation, we'll first have to make sense of the data. The necessary steps to do this:\n",
        "\n",
        "1) Load the data from the CSV into a DataFrame. (Assume a dog_rates_tweets.csv file is in the same folder as the notebook file.)\n",
        "\n",
        "2) Find tweets that contain an “/10” rating (because not all do). Extract the numeric rating. Exclude tweets that don't contain a rating.\n",
        "\n",
        "3) Remove outliers: there are a few obvious ones. Exclude rating values that are too large to make sense. (Maybe larger than 25/10?)\n",
        "\n",
        "4) Make sure the 'created_at' column is a datetime value, not a string. This is important for the plots.\n",
        "\n",
        "5) Create a scatter plot of date vs rating, so you can see what the data looks like.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1UWKVjdueM",
        "colab_type": "text"
      },
      "source": [
        "### Loading libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLCmRjD-mHfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Loading important libraries\n",
        "'''\n",
        "import pandas as pd             #dataset management\n",
        "import numpy as np              #dataset management\n",
        "import matplotlib.pyplot as plt #plot construction \n",
        "import re                       #data transformation \n",
        "import datetime                 #data transformation\n",
        "from scipy import stats         #data science model \n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIPVzMhldx30",
        "colab_type": "text"
      },
      "source": [
        "### Routines to pre-process the dataset \n",
        "\n",
        "This regular expression extractor will look for \"n/10\" strings in the format they seem to occur in the tweets. if this is found by searching in a tweet, then the resulting match object can be used to get the numeric rating as a string, which can then be converted to a float/number. \n",
        "\n",
        "To make easier to \"exclude\" some rows from the dataframe is to return None for rating values that aren't valid ratings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq73yg58mHfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Routine to extract the rating\n",
        "'''\n",
        "rating_re = re.compile(r'(\\d+(\\.\\d+)?)/10')\n",
        "def get_rating(text):\n",
        "    m = rating_re.search(text)\n",
        "    if m:\n",
        "        rate = float(m.group(1))\n",
        "        #return rate\n",
        "        if rate > 20:\n",
        "            return None\n",
        "        else:\n",
        "            return rate\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "get_rating = np.vectorize(get_rating, otypes=[np.float])\n",
        "\n",
        "'''Routine to extract tweet time'''\n",
        "def parse_date(d):\n",
        "    return datetime.datetime.strptime(d, '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "parse_date = np.vectorize(parse_date, otypes=[np.object_])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7eJtwJ3d33Z",
        "colab_type": "text"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J9pEu9imHft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Loading the dataset\n",
        "'''\n",
        "data = pd.read_csv('/dog_rates_tweets.csv', parse_dates=[1])\n",
        "data.shape # rows x columns \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVgkLI6jd7zw",
        "colab_type": "text"
      },
      "source": [
        "### Transforming the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18P2ys_obE6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Checking the dataset'''\n",
        "print(data.head())\n",
        "\n",
        "'''Extracting the rating'''\n",
        "data['rating'] = get_rating(data['text']) \n",
        "print('\\n\\nDataset with new column')\n",
        "print(data.head(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqFIdpcqgRlB",
        "colab_type": "text"
      },
      "source": [
        "The spicy.stats.linregress function can do a linear regression for us, but it works on numbers, not datatime objects. Datetime objects have a .timestamp() method that will give us a number (of seconds after a specific point), but we need to get that into our data before using it.  If you write a function to_timestamp then you can do: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-2khujWsKev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Dataset size:', data.shape)\n",
        "\n",
        "'''Removing lines that dont have ratings'''\n",
        "data = data[data['rating'].notnull()] \n",
        "print('New dataset size:', data.shape)\n",
        "\n",
        "'''Organazing the time'''\n",
        "data['timestamp'] = data['created_at'].apply(lambda d: d.timestamp())\n",
        "\n",
        "print('\\n\\nNew Dataset')\n",
        "print(data.head())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAsiCF2-eBTx",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the model\n",
        "\n",
        "You can then use linregress to get a slope and intercept for a best fit line. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAWAtHJSmHfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit = stats.linregress(data['timestamp'], data['rating'])\n",
        "data['prediction'] = data['timestamp']*fit.slope + fit.intercept\n",
        "fit.slope, fit.intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqvR0hQleGEE",
        "colab_type": "text"
      },
      "source": [
        "### Creating the graphic \n",
        "\n",
        "To plot the best-fit line, the  values must be datetime objects, not the timestamps. To add the best-fit line, you can plot data['created_at'] against data['timestamp']*fit.slope + fit.intercept to get a fit line (assuming you stored the results of linregress in a variable fit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jj1zVb9mHfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.xticks(rotation=25)\n",
        "plt.plot(data['created_at'], data['rating'], 'b.', alpha=0.5)\n",
        "plt.plot(data['created_at'], data['prediction'], 'r-', linewidth=3)\n",
        "plt.xlabel('Created at')\n",
        "plt.ylabel('Rating/Prediction')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}